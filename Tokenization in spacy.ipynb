{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02f760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "950ee16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56802a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nlp('''Dr.Strange loves pav bhaji of mumbai as it costs only 2$ per plate.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a120c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0=Dr.Strange loves pav bhaji of mumbai as it costs only 2$ per plate.\n"
     ]
    }
   ],
   "source": [
    "for i, sent in enumerate(text.sents):\n",
    "    print(f'{i}={sent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d62f405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for sent in text.sents:\n",
    "    for word in sent:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ee26ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc32760a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DNK133\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69992738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57b7558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr. strange loves pav bhaji of mumbai as it costs only 2$ per plate.']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize('Dr. strange loves pav bhaji of mumbai as it costs only 2$ per plate.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97012eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp2 = spacy.blank('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc1479cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b4319c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "token2 = nlp2('''Dr. strange loves pav bhaji of mumbai as it costs only 2$ per plate.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39497178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "864eea2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in token2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a22af281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54084e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bhaji'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = token2[4]\n",
    "word.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2dcf61d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bhaji"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452c11aa",
   "metadata": {},
   "source": [
    "### Span object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b747dc42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'haj'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.text[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5c37730",
   "metadata": {},
   "outputs": [],
   "source": [
    "span4 = token2[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b57ced9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strange loves pav bhaji"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "281ac36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(span4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2125f1a",
   "metadata": {},
   "source": [
    "### token attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08d09837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr. strange loves pav bhaji of mumbai as it costs only 2$ per plate."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9265bbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = token2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ecf7246",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9db9c734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3e3211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_token = nlp2('tony gave two $ to peter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce530f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = new_token[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1888eac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cbaabc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = new_token[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2db13ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "525c4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Dayton high school, 8th grade students information\\n',\n",
    " '==================================================\\n',\n",
    " '\\n',\n",
    " 'Name\\tbirth day   \\temail\\n',\n",
    " '-----\\t------------\\t------\\n',\n",
    " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
    " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
    " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
    " 'Joe      1 May, 1997    joe@root.com\\n',\n",
    " '\\n',\n",
    " '\\n',\n",
    " '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff1bd4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n==================================================\\n\\nName\\tbirth day   \\temail\\n-----\\t------------\\t------\\nVirat   5 June, 1882    virat@kohli.com\\nMaria\\t12 April, 2001  maria@sharapova.com\\nSerena  24 June, 1998   serena@williams.com \\nJoe      1 May, 1997    joe@root.com\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ''.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5c2f16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dayton high school, 8th grade students information\n",
       "==================================================\n",
       "\n",
       "Name\tbirth day   \temail\n",
       "-----\t------------\t------\n",
       "Virat   5 June, 1882    virat@kohli.com\n",
       "Maria\t12 April, 2001  maria@sharapova.com\n",
       "Serena  24 June, 1998   serena@williams.com \n",
       "Joe      1 May, 1997    joe@root.com\n",
       "\n",
       "\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp2(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3752395e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email.append(token.text)\n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d29ed45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "भैया False\n",
      "जी False\n",
      "! False\n",
      "5000 False\n",
      "₹ True\n",
      "उधार False\n",
      "थे False\n",
      "वो False\n",
      "वापस False\n",
      "देदो False\n"
     ]
    }
   ],
   "source": [
    "nlp3 = spacy.blank(\"hi\")\n",
    "doc3 = nlp(\"भैया जी! 5000 ₹ उधार थे वो वापस देदो\")\n",
    "for token in doc3:\n",
    "    print(token, token.is_currency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1283af",
   "metadata": {},
   "source": [
    "### Customizing tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "319fe9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3dbb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94d555e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token = [token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a1f4cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.tokenizer.add_special_case('gimme',[\n",
    "    {ORTH: 'gim'},\n",
    "    {ORTH: 'me'}\n",
    "])\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "token = [token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581af67b",
   "metadata": {},
   "source": [
    "### Sentence Tokenization or Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "339fbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp2('''To find dates using Spacy in Python, you need to use Spacy's entity recognition capabilities. Spacy provides a pre-trained statistical model that can identify entities like dates, names, locations, etc. You can use this model to extract dates from text.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65bb54a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token)\n",
      "File \u001b[1;32mD:\\Dnk_project\\proenv\\lib\\site-packages\\spacy\\tokens\\doc.pyx:924\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "for token in doc.sents:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d34520ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "785904b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x17eebc0fec0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6b8091b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x17eebc0fec0>)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp2.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c33c7100",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp2('''To find dates using Spacy in Python, you need to use Spacy's entity recognition capabilities. Spacy provides a pre-trained statistical model that can identify entities like dates, names, locations, etc. You can use this model to extract dates from text.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16bfe2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find dates using Spacy in Python, you need to use Spacy's entity recognition capabilities.\n",
      "Spacy provides a pre-trained statistical model that can identify entities like dates, names, locations, etc.\n",
      "You can use this model to extract dates from text.\n"
     ]
    }
   ],
   "source": [
    "for token in doc.sents:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "959256cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: token has an attribute that can be used to detect a url\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dddbd76d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Look for data to help you address the question. Governments are good\n",
       "sources because data from public research is often freely available. Good\n",
       "places to start include http://www.data.gov/, and http://www.science.\n",
       "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
       "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
       "and the European Social Survey at http://www.europeansocialsurvey.org/."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dfa2551a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.data.gov/',\n",
       " 'http://www.science',\n",
       " 'http://data.gov.uk/.',\n",
       " 'http://www3.norc.org/gss+website/',\n",
       " 'http://www.europeansocialsurvey.org/.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = []\n",
    "for token in doc:\n",
    "    if token.like_url:\n",
    "        url.append(token.text)\n",
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "172bba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tony gave two $ to Peter, Bruce gave 500 € to Steve'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "\n",
    "# TODO: Write code here\n",
    "# Hint: Use token.i for the index of a token and token.is_currency for currency symbol detection\n",
    "\n",
    "doc1 = nlp2(transactions)\n",
    "doc1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06b1aeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    if token.like_num and doc1[token.i+1].is_currency:\n",
    "        print(token.text, doc1[token.i+1].text) \n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
